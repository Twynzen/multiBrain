# Documentaci贸n del Proyecto: Integraci贸n de GPT-3.5-turbo con FastAPI

## Resumen

El objetivo de este proyecto es desarrollar un sistema de backend utilizando FastAPI que permita almacenar y gestionar memorias y textos de personalizaci贸n de personajes, conectarlo con la API de GPT-3.5-turbo de OpenAI y ofrecer servicios para convertir texto a audio y audio a texto.

## Requisitos

### Conexi贸n a FastAPI

1. Crear un nuevo proyecto en FastAPI.
2. Configurar la base de datos para almacenar la informaci贸n de los personajes y sus instancias.

### Modelo de datos

Crear los siguientes modelos para almacenar la informaci贸n de los personajes y sus instancias:

1. **Personaje**: Contendr谩 la informaci贸n b谩sica de un personaje, como su descripci贸n e identificador.
   - Descripci贸n: Texto que describe al personaje.
   - ID: Identificador 煤nico del personaje.

2. **Instancia**: Representar谩 una variaci贸n de un personaje basada en la personalidad del personaje contenedor, pero con una memoria y nombre diferentes.
   - Nombre: Nombre 煤nico de la instancia.
   - Memoria: Texto que representa la memoria espec铆fica de la instancia.
   - Personaje: Referencia al personaje contenedor.

### Integraci贸n con la API de GPT-3.5-turbo

1. Instalar la biblioteca de OpenAI en el proyecto.
2. Crear una funci贸n que realice solicitudes a la API de GPT-3.5-turbo, utilizando la informaci贸n del personaje y su instancia para personalizar las respuestas.
3. Manejar las respuestas de la API y retornar el texto generado.

### Conversi贸n de texto a audio y audio a texto

1. Investigar e implementar bibliotecas o servicios adecuados para convertir texto a audio y viceversa.
2. Integrar estos servicios en el backend.

## Proceso de desarrollo

1. **Configuraci贸n del entorno FastAPI**: Instalar FastAPI y configurar el proyecto, incluyendo la base de datos y el modelo de datos.

2. **Implementaci贸n del modelo de datos**: Crear los modelos `Personaje` e `Instancia` con sus respectivos campos y relaciones en FastAPI.

3. **Integraci贸n con la API de GPT-3.5-turbo**: Instalar la biblioteca de OpenAI y desarrollar las funciones necesarias para interactuar con la API.

4. **Creaci贸n del backend**: Implementar el backend que gestione las solicitudes y respuestas a la API de GPT-3.5-turbo, utilizando la informaci贸n almacenada en la base de datos.

5. **Integraci贸n de servicios de conversi贸n**: Integrar los servicios de conversi贸n de texto a audio y audio a texto en el backend.

6. **Pruebas y ajustes**: Probar la funcionalidad del sistema y realizar ajustes seg煤n sea necesario para lograr respuestas personalizadas, llamativas y la conversi贸n adecuada entre texto y audio.

## Resultados esperados

Al finalizar el proyecto, se espera contar con un sistema de backend que permita almacenar y gestionar personajes e instancias, generar respuestas personalizadas y llamativas utilizando la API de GPT-3.5-turbo de OpenAI, y ofrecer servicios para convertir texto a audio y

# Llamada a la API de GPT-3.5-turbo

## Requisitos previos

1. Instalar la biblioteca de OpenAI: `pip install openai`
2. La API se la pide a Daniel

## Recomendaci贸n para gestionar la API key

Es importante mantener la API key segura y no incluirla directamente en el c贸digo. Para ello, se recomienda utilizar variables de entorno:

1. Crear un archivo `.env` en el directorio ra铆z del proyecto.
2. Agregar la API key en el archivo `.env` de la siguiente manera: `OPENAI_API_KEY=tu_api_key`
3. Instalar la biblioteca `python-dotenv`: `pip install python-dotenv`
4. En el archivo donde necesites utilizar la API key, importar `load_dotenv` y cargar las variables de entorno del archivo `.env`:

```python
from dotenv import load_dotenv
import os

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
```

## Llamada a la API de GPT-3.5-turbo

1. Importar la biblioteca de OpenAI y configurar la API key:

```python
import openai

openai.api_key = api_key
```

2. Crear una funci贸n para llamar a la API de GPT-3.5-turbo:

```python

def generate_text(prompt, model="gpt-3.5-turbo", max_tokens=100):
    response = openai.Completion.create(
    engine=model,
    prompt=prompt,
    max_tokens=max_tokens,
    n=1,
    stop=None,
    temperature=1.0,
)

return response.choices[0].text.strip()
```

3. Utilizar la funci贸n `generate_text` para obtener respuestas del modelo GPT-3.5-turbo:

```python
prompt = "Escribe una breve descripci贸n de un parque."
generated_text = generate_text(prompt)
print(generated_text)
```

Se puede personalizar los par谩metros de la funci贸n `generate_text` seg煤n tus necesidades, como el n煤mero m谩ximo de tokens, la temperatura, entre otros.

## Getting start

1. Create a virtual environment with python venv, I recommend to use WSL 2 `python3 -m venv env` and use this command to activate the env `source env/bin/activate`

2. Install dependencies with pip3 using the requirements.txt file
`pip3 install -r requirements.txt`

3. Run this command
`uvicorn main:app --reload --port 8011`

Use this URL to see the endpoints:
`http://localhost:8011/docs`

## Preguntas

1. Cuando se ejecuta 驴Qu茅 es lo que hace actualmente el programa? 
2. Podr铆a darme un mapa de la arquitectura. Ojala dibujadito jaja #Todo
3. Podr铆a darme instrucci贸n de alguna tarea para ver si puedo ayudar a implementar cosas
4. Podr铆a indicarme como se vincula con docker?
5. Aclarme si el entorno virtual que se usa apra ejecutar el proyecto 驴c贸mo funciona?
